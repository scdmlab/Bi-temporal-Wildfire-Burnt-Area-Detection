{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ec77f35",
   "metadata": {},
   "source": [
    "# Wildfire Burnt Area Detection - Quick Start Example\n",
    "\n",
    "This notebook demonstrates how to use the Bi-temporal Attention U-Net for wildfire burnt area detection in remote sensing images.\n",
    "\n",
    "## üìã Contents\n",
    "1. [Setup and Installation](#setup)\n",
    "2. [Data Preparation](#data)\n",
    "3. [Model Training](#training)\n",
    "4. [Inference](#inference)\n",
    "5. [Visualization](#visualization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89aac5db",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation <a id=\"setup\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4b814c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (uncomment if needed)\n",
    "# !pip install torch torchvision opencv-python albumentations pillow matplotlib seaborn scikit-learn pyyaml tqdm\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path('..').resolve()\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18365455",
   "metadata": {},
   "source": [
    "## 2. Data Preparation <a id=\"data\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f052bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_utils import analyze_dataset, check_file_naming, visualize_random_samples\n",
    "\n",
    "# Set your data paths\n",
    "data_dir = \"path/to/your/wildfire_data\"  # Update this path\n",
    "pre_dir = os.path.join(data_dir, \"pre_fire\")\n",
    "post_dir = os.path.join(data_dir, \"post_fire\")\n",
    "mask_dir = os.path.join(data_dir, \"burnt_masks\")\n",
    "\n",
    "# Check if directories exist\n",
    "for directory in [pre_dir, post_dir]:\n",
    "    if not os.path.exists(directory):\n",
    "        print(f\"‚ö†Ô∏è  Directory not found: {directory}\")\n",
    "        print(\"Please update the data_dir path above\")\n",
    "    else:\n",
    "        print(f\"‚úÖ Found directory: {directory}\")\n",
    "\n",
    "# Analyze dataset (uncomment when you have data)\n",
    "# stats = analyze_dataset(pre_dir, post_dir, mask_dir)\n",
    "# naming = check_file_naming(pre_dir, post_dir, mask_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccdc1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize random samples from your wildfire dataset\n",
    "# visualize_random_samples(pre_dir, post_dir, mask_dir, n_samples=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c474d2d3",
   "metadata": {},
   "source": [
    "## 3. Model Training <a id=\"training\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1f11e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.attention_unet import get_model\n",
    "from datasets.bitemporal_dataset import BiTemporalDataset\n",
    "from utils.losses import get_loss_function\n",
    "from utils.metrics import calculate_metrics\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Load configuration\n",
    "with open('../configs/config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(\"Configuration loaded:\")\n",
    "print(f\"Model type: {config['model']['type']}\")\n",
    "print(f\"Image size: {config['data']['image_size']}\")\n",
    "print(f\"Batch size: {config['training']['batch_size']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff704d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = get_model(config['model']['type'], **config['model']['params'])\n",
    "model.to(device)\n",
    "\n",
    "print(f\"Model created: {config['model']['type']}\")\n",
    "print(f\"Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6011af00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model with dummy data\n",
    "batch_size = 64\n",
    "image_size = config['data']['image_size']\n",
    "\n",
    "# Create dummy input\n",
    "x_pre = torch.randn(batch_size, 3, image_size[0], image_size[1]).to(device)\n",
    "x_post = torch.randn(batch_size, 3, image_size[0], image_size[1]).to(device)\n",
    "\n",
    "# Test forward pass\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    if 'bitemporal' in config['model']['type']:\n",
    "        output = model(x_pre, x_post)\n",
    "    else:\n",
    "        # Concatenate for single-input models\n",
    "        x_concat = torch.cat([x_pre, x_post], dim=1)\n",
    "        output = model(x_concat)\n",
    "\n",
    "print(f\"‚úÖ Model test successful!\")\n",
    "print(f\"Input shape: {x_pre.shape} + {x_post.shape}\")\n",
    "print(f\"Output shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f9392d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset and dataloader (uncomment when you have data)\n",
    "# dataset = BiTemporalDataset(\n",
    "#     pre_dir=pre_dir,\n",
    "#     post_dir=post_dir,\n",
    "#     mask_dir=mask_dir,\n",
    "#     image_size=config['data']['image_size'],\n",
    "#     normalize=config['data']['normalize']\n",
    "# )\n",
    "\n",
    "# dataloader = DataLoader(\n",
    "#     dataset,\n",
    "#     batch_size=config['training']['batch_size'],\n",
    "#     shuffle=True,\n",
    "#     num_workers=2\n",
    "# )\n",
    "\n",
    "# print(f\"Wildfire dataset size: {len(dataset)}\")\n",
    "# print(f\"Batch size: {config['training']['batch_size']}\")\n",
    "# print(f\"Number of batches: {len(dataloader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a190521e",
   "metadata": {},
   "source": [
    "## 4. Training Loop (Simplified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566b3364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup training components\n",
    "loss_fn = get_loss_function(\n",
    "    config['loss']['type'], \n",
    "    **config['loss']['params']\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), \n",
    "    lr=config['training']['lr'],\n",
    "    weight_decay=config['training']['weight_decay']\n",
    ")\n",
    "\n",
    "print(\"Training components initialized:\")\n",
    "print(f\"Loss function: {config['loss']['type']}\")\n",
    "print(f\"Optimizer: Adam (lr={config['training']['lr']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4147ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplified training loop (for demonstration)\n",
    "def train_one_epoch(model, dataloader, loss_fn, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch_idx, (pre_imgs, post_imgs, targets) in enumerate(dataloader):\n",
    "        pre_imgs = pre_imgs.to(device)\n",
    "        post_imgs = post_imgs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        if 'bitemporal' in config['model']['type']:\n",
    "            outputs = model(pre_imgs, post_imgs)\n",
    "        else:\n",
    "            concat_imgs = torch.cat([pre_imgs, post_imgs], dim=1)\n",
    "            outputs = model(concat_imgs)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f'Batch {batch_idx}/{len(dataloader)}, Loss: {loss.item():.4f}')\n",
    "    \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "# For actual training, uncomment:\n",
    "# num_epochs = 5\n",
    "# for epoch in range(num_epochs):\n",
    "#     avg_loss = train_one_epoch(model, dataloader, loss_fn, optimizer, device)\n",
    "#     print(f'Epoch {epoch+1}/{num_epochs}, Average Loss: {avg_loss:.4f}')\n",
    "\n",
    "print(\"Training function defined. Uncomment the training loop to start training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0fa18c",
   "metadata": {},
   "source": [
    "## 5. Inference <a id=\"inference\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d108e5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pretrained model (if available)\n",
    "# model_path = \"path/to/your/trained_model.pth\"\n",
    "# if os.path.exists(model_path):\n",
    "#     checkpoint = torch.load(model_path, map_location=device)\n",
    "#     model.load_state_dict(checkpoint)\n",
    "#     print(f\"‚úÖ Model loaded from {model_path}\")\n",
    "# else:\n",
    "#     print(\"No pretrained model found. Using randomly initialized model for demonstration.\")\n",
    "\n",
    "model.eval()\n",
    "print(\"Model set to evaluation mode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd03107b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference function\n",
    "def predict_burnt_area(model, pre_img, post_img, device):\n",
    "    \"\"\"\n",
    "    Predict burnt areas between pre-fire and post-fire images\n",
    "    \n",
    "    Args:\n",
    "        model: Trained model\n",
    "        pre_img: Pre-fire image tensor [1, 3, H, W]\n",
    "        post_img: Post-fire image tensor [1, 3, H, W]\n",
    "        device: Device to run inference on\n",
    "    \n",
    "    Returns:\n",
    "        prediction: Binary burnt area mask [H, W]\n",
    "        probability: Burnt area probability map [H, W]\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pre_img = pre_img.to(device)\n",
    "        post_img = post_img.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        if 'bitemporal' in config['model']['type']:\n",
    "            output = model(pre_img, post_img)\n",
    "        else:\n",
    "            concat_img = torch.cat([pre_img, post_img], dim=1)\n",
    "            output = model(concat_img)\n",
    "        \n",
    "        # Convert to probability\n",
    "        if output.shape[1] == 1:  # Binary segmentation\n",
    "            probability = torch.sigmoid(output).cpu().numpy()[0, 0]\n",
    "        else:  # Multi-class\n",
    "            probability = torch.softmax(output, dim=1).cpu().numpy()[0, 1]\n",
    "        \n",
    "        # Binary prediction\n",
    "        prediction = (probability > 0.5).astype(np.uint8)\n",
    "        \n",
    "    return prediction, probability\n",
    "\n",
    "print(\"Wildfire burnt area inference function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf18f75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo inference with dummy data\n",
    "# Create dummy test images\n",
    "test_pre = torch.randn(1, 3, *config['data']['image_size'])\n",
    "test_post = torch.randn(1, 3, *config['data']['image_size'])\n",
    "\n",
    "# Run wildfire burnt area detection\n",
    "pred, prob = predict_burnt_area(model, test_pre, test_post, device)\n",
    "\n",
    "print(f\"‚úÖ Wildfire detection inference completed!\")\n",
    "print(f\"Prediction shape: {pred.shape}\")\n",
    "print(f\"Probability range: [{prob.min():.3f}, {prob.max():.3f}]\")\n",
    "print(f\"Burnt pixels: {np.sum(pred)} / {pred.size} ({np.sum(pred)/pred.size*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870777fa",
   "metadata": {},
   "source": [
    "## 6. Visualization <a id=\"visualization\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf9d4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize prediction results\n",
    "def visualize_prediction(pre_img, post_img, prediction, probability, title=\"Wildfire Burnt Area Detection Result\"):\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "    \n",
    "    # Convert tensors to numpy for visualization\n",
    "    if isinstance(pre_img, torch.Tensor):\n",
    "        pre_np = pre_img.cpu().numpy()[0].transpose(1, 2, 0)\n",
    "        pre_np = (pre_np - pre_np.min()) / (pre_np.max() - pre_np.min())\n",
    "    else:\n",
    "        pre_np = pre_img\n",
    "    \n",
    "    if isinstance(post_img, torch.Tensor):\n",
    "        post_np = post_img.cpu().numpy()[0].transpose(1, 2, 0)\n",
    "        post_np = (post_np - post_np.min()) / (post_np.max() - post_np.min())\n",
    "    else:\n",
    "        post_np = post_img\n",
    "    \n",
    "    # Pre-fire image\n",
    "    axes[0].imshow(pre_np)\n",
    "    axes[0].set_title('Pre-fire')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Post-fire image\n",
    "    axes[1].imshow(post_np)\n",
    "    axes[1].set_title('Post-fire')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    # Probability map\n",
    "    im2 = axes[2].imshow(probability, cmap='hot', vmin=0, vmax=1)\n",
    "    axes[2].set_title('Burnt Area Probability')\n",
    "    axes[2].axis('off')\n",
    "    plt.colorbar(im2, ax=axes[2], fraction=0.046, pad=0.04)\n",
    "    \n",
    "    # Binary prediction overlay\n",
    "    axes[3].imshow(post_np)\n",
    "    # Create red overlay for burnt areas\n",
    "    overlay = np.zeros_like(post_np)\n",
    "    overlay[prediction == 1] = [1, 0, 0]  # Red for burnt areas\n",
    "    axes[3].imshow(overlay, alpha=0.6)\n",
    "    axes[3].set_title('Burnt Area Overlay')\n",
    "    axes[3].axis('off')\n",
    "    \n",
    "    plt.suptitle(title, fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize the demo result\n",
    "visualize_prediction(test_pre, test_post, pred, prob, \"Wildfire Burnt Area Demo Result\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43368c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of how to process real images (when you have data)\n",
    "from utils.visualize import save_prediction_overlay\n",
    "\n",
    "def process_image_pair(pre_path, post_path, model, device, config):\n",
    "    \"\"\"\n",
    "    Process a single image pair for wildfire burnt area detection\n",
    "    \"\"\"\n",
    "    from torchvision import transforms\n",
    "    \n",
    "    # Define transforms\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(config['data']['image_size']),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]) if config['data']['normalize'] else transforms.Lambda(lambda x: x)\n",
    "    ])\n",
    "    \n",
    "    # Load and preprocess images\n",
    "    pre_img = Image.open(pre_path).convert('RGB')\n",
    "    post_img = Image.open(post_path).convert('RGB')\n",
    "    \n",
    "    pre_tensor = transform(pre_img).unsqueeze(0)\n",
    "    post_tensor = transform(post_img).unsqueeze(0)\n",
    "    \n",
    "    # Run wildfire detection inference\n",
    "    prediction, probability = predict_burnt_area(model, pre_tensor, post_tensor, device)\n",
    "    \n",
    "    # Visualize\n",
    "    visualize_prediction(pre_tensor, post_tensor, prediction, probability, \n",
    "                        f\"Wildfire Detection Result: {os.path.basename(pre_path)}\")\n",
    "    \n",
    "    return prediction, probability\n",
    "\n",
    "# Example usage (uncomment when you have actual image files):\n",
    "# pre_fire_path = \"path/to/pre_fire_image.jpg\"\n",
    "# post_fire_path = \"path/to/post_fire_image.jpg\"\n",
    "# \n",
    "# if os.path.exists(pre_fire_path) and os.path.exists(post_fire_path):\n",
    "#     pred, prob = process_image_pair(pre_fire_path, post_fire_path, model, device, config)\n",
    "#     print(f\"Wildfire detection completed for {os.path.basename(pre_fire_path)}\")\n",
    "\n",
    "print(\"Wildfire image processing function defined. Uncomment to process real images.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2302da5f",
   "metadata": {},
   "source": [
    "## üéØ Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **Setup**: Loading the Bi-temporal Attention U-Net framework for wildfire detection\n",
    "2. **Data Analysis**: Tools to analyze your wildfire dataset structure\n",
    "3. **Model Creation**: Instantiating different model architectures for burnt area detection\n",
    "4. **Training**: Basic training loop structure for wildfire detection models\n",
    "5. **Inference**: Running burnt area detection on pre/post-fire image pairs\n",
    "6. **Visualization**: Displaying results with overlays and probability maps\n",
    "\n",
    "## üöÄ Next Steps\n",
    "\n",
    "1. **Prepare your data**: Organize into pre_fire/post_fire/burnt_masks directories\n",
    "2. **Update paths**: Modify the data directory paths in this notebook\n",
    "3. **Configure model**: Adjust `configs/config.yaml` for your specific wildfire detection needs\n",
    "4. **Train model**: Use `scripts/train.py` for full training pipeline\n",
    "5. **Evaluate**: Use `scripts/evaluate.py` for comprehensive evaluation\n",
    "\n",
    "## üìö Documentation\n",
    "\n",
    "- See `README.md` for detailed setup instructions\n",
    "- Check `configs/config.yaml` for all configuration options\n",
    "- Explore `utils/` for additional functionality\n",
    "\n",
    "Happy wildfire detection! üõ∞Ô∏èüî•üîç"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
